export const chatWithAI = async (
  prompt: string,
  chatId: string,
  onChunk: (chunk: string) => void,
  onError: (error: Error) => void,
  signal?: AbortSignal
): Promise<void> => {
  try {
    // ğŸ”‘ 1. ä» localStorageï¼ˆæˆ–ä½ çš„çŠ¶æ€ç®¡ç†ï¼‰è·å– token
    const token = localStorage.getItem('token'); // ğŸ‘ˆ æ ¹æ®ä½ å®é™…å­˜çš„ key è°ƒæ•´
    if (!token) {
      throw new Error('ç”¨æˆ·æœªç™»å½•ï¼Œè¯·å…ˆç™»å½•');
    }

    const response = await fetch('/api/v1/ai/chat', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`, // ğŸ”‘ 2. æ·»åŠ è¿™ä¸€è¡Œï¼
      },
      body: JSON.stringify({
        prompt,
        chatSessionId: chatId,
      }),
      signal,
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`HTTP ${response.status}: ${errorText}`);
    }

    if (!response.body) {
      throw new Error('ReadableStream not supported');
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder('utf-8');

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      const chunk = decoder.decode(value, { stream: true });
      onChunk(chunk);
    }
  } catch (error) {
    if ((error as Error).name !== 'AbortError') {
      onError(error as Error);
    }
  }
};
